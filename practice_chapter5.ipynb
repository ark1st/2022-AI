{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 데이터 준비\n",
    "- 캐글 __Dogs vs. Cats__ 데이터셋 \n",
    "- https://www.kaggle.com/c/dogs-vs-cats/data 에서 다운로드 가능 (캐글 로그인 필요)\n",
    "- 다운로드 받은 데이터셋 파일(dogs-vs-cats.zip) 압축해제 및 그 안의 train.zip 파일 압축해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_1184\\676833354.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mglob\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mshutil\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from utils import log_progress\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 경로\n",
    "files = glob.glob('train/*')\n",
    "files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 파일명을 통해 cat 파일, dog 파일 분리\n",
    "cat_files = [fn for fn in files if 'cat' in fn]\n",
    "dog_files = [fn for fn in files if 'dog' in fn]\n",
    "\n",
    "len(cat_files), len(dog_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이렇게 한번에 해도 됨...\n",
    "# cat_files = glob.glob('train/cat.*') \n",
    "# dog_files = glob.glob('train/dog.*') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습데이터/검증데이터/테스트데이터 분리 \n",
    "# cf) sklearn의 sklearn.model_selection.train_test_split() 사용하면 편리 (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "cat_train = np.random.choice(cat_files, size=1500, replace=False)\n",
    "dog_train = np.random.choice(dog_files, size=1500, replace=False)\n",
    "cat_files = list(set(cat_files) - set(cat_train))\n",
    "dog_files = list(set(dog_files) - set(dog_train))\n",
    "\n",
    "cat_val = np.random.choice(cat_files, size=500, replace=False)\n",
    "dog_val = np.random.choice(dog_files, size=500, replace=False)\n",
    "cat_files = list(set(cat_files) - set(cat_val))\n",
    "dog_files = list(set(dog_files) - set(dog_val))\n",
    "\n",
    "cat_test = np.random.choice(cat_files, size=500, replace=False)\n",
    "dog_test = np.random.choice(dog_files, size=500, replace=False)\n",
    "\n",
    "print('Cat datasets:', cat_train.shape, cat_val.shape, cat_test.shape)\n",
    "print('Dog datasets:', dog_train.shape, dog_val.shape, dog_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습데이터/검증데이터/테스트데이터 각각 별도의 파일을 만들어서 저장\n",
    "train_dir = 'training_data'\n",
    "val_dir = 'validation_data'\n",
    "test_dir = 'test_data'\n",
    "\n",
    "# cat, dog 데이터를 결합\n",
    "train_files = np.concatenate([cat_train, dog_train]) \n",
    "validate_files = np.concatenate([cat_val, dog_val])\n",
    "test_files = np.concatenate([cat_test, dog_test])\n",
    "\n",
    "# 각 경로가 없으면 새로 만듦.\n",
    "os.mkdir(train_dir) if not os.path.isdir(train_dir) else None\n",
    "os.mkdir(val_dir) if not os.path.isdir(val_dir) else None\n",
    "os.mkdir(test_dir) if not os.path.isdir(test_dir) else None\n",
    "\n",
    "# 학습데이터/검증데이터/테스트데이터 경로에 원본 파일 복사\n",
    "for fn in log_progress(train_files, name='Training Images'):\n",
    "    shutil.copy(fn, train_dir)\n",
    "\n",
    "for fn in log_progress(validate_files, name='Validation Images'):\n",
    "    shutil.copy(fn, val_dir)\n",
    "    \n",
    "for fn in log_progress(test_files, name='Test Images'):\n",
    "    shutil.copy(fn, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 합성곱 신경망(CNN) 모델 처음부터 구축하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습 데이터 / 검증 데이터 준비\n",
    "# 이미지의 가로,세로 사이즈는 150,150이고 빨강, 녹색, 파랑(RGB)인 3개의 채널이 있으므로 \n",
    "# 출력되는 shape은 (데이터 갯수, 150, 150, 3)의 형태. \n",
    "\n",
    "IMG_DIM = (150, 150)\n",
    "\n",
    "# 학습 데이터 \n",
    "train_files = glob.glob('training_data/*')\n",
    "train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in train_files]\n",
    "train_imgs = np.array(train_imgs)\n",
    "train_labels = [fn.split('/')[1].split('.')[0].strip() for fn in train_files]\n",
    "\n",
    "# 검증 데이터\n",
    "validation_files = glob.glob('validation_data/*')\n",
    "validation_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in validation_files]\n",
    "validation_imgs = np.array(validation_imgs)\n",
    "validation_labels = [fn.split('/')[1].split('.')[0].strip() for fn in validation_files]\n",
    "\n",
    "print('Train dataset shape:', train_imgs.shape, \n",
    "      '\\nValidation dataset shape:', validation_imgs.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 샘플 확인\n",
    "print(train_imgs[0].shape)\n",
    "array_to_img(train_imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 텍스트 클래스 레이블 인코딩\n",
    "# cat : 0, dog : 1\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_enc = le.transform(train_labels)\n",
    "validation_labels_enc = le.transform(validation_labels)\n",
    "\n",
    "print('Before Encoding : ', train_labels[1495:1505], \n",
    "      '\\nAfter Encoding : ', train_labels_enc[1495:1505])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 데이터 증강 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = glob.glob('training_data/*')\n",
    "train_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,\n",
    "                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, \n",
    "                                   horizontal_flip=True, fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 증강된 고양이 이미지 샘플\n",
    "img_id = 2595\n",
    "cat_generator = train_datagen.flow(train_imgs[img_id:img_id+1], train_labels[img_id:img_id+1],\n",
    "                                   batch_size=1)\n",
    "cat = [next(cat_generator) for i in range(0,5)]\n",
    "fig, ax = plt.subplots(1,5, figsize=(16, 6))\n",
    "print('Labels:', [item[1][0] for item in cat])\n",
    "l = [ax[i].imshow(cat[i][0][0]) for i in range(0,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 증강된 강아지 이미지 샘플\n",
    "img_id = 1991\n",
    "dog_generator = train_datagen.flow(train_imgs[img_id:img_id+1], train_labels[img_id:img_id+1],\n",
    "                                   batch_size=1)\n",
    "dog = [next(dog_generator) for i in range(0,5)]\n",
    "fig, ax = plt.subplots(1,5, figsize=(15, 6))\n",
    "print('Labels:', [item[1][0] for item in dog])\n",
    "l = [ax[i].imshow(dog[i][0][0]) for i in range(0,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 하이퍼 파라미터 설정\n",
    "batch_size = 100 # 배치 사이즈 : 반복해서 모델에 전달되는 데이터의 수\n",
    "num_classes = 2 # 클래스 개수 (cat, dog)\n",
    "epochs = 100 # 에포크 : 학습하는동안 모델에 전달하는 전체 데이터 세트를 횟수\n",
    "input_shape = (150, 150, 3) # 입력되는 이미지 사이즈 (가로사이즈, 세로사이즈, 채널 수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN 모델 컴파일 및 요약 정보 확인\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모델 학습\n",
    "train_generator = train_datagen.flow(train_imgs, train_labels_enc, batch_size=batch_size)\n",
    "val_generator = val_datagen.flow(validation_imgs, validation_labels_enc, batch_size=batch_size)\n",
    "\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=epochs,\n",
    "                              validation_data=val_generator, validation_steps=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "t = f.suptitle('CNN with Image Augmentation Performance', fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "epoch_list = list(range(1, epochs+1))\n",
    "ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n",
    "ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_xticks(np.arange(0, 101, 10))\n",
    "ax1.set_ylabel('Accuracy Value')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_title('Accuracy')\n",
    "l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
    "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_xticks(np.arange(0, 101, 10))\n",
    "ax2.set_ylabel('Loss Value')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_title('Loss')\n",
    "l2 = ax2.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cats_dogs_cnn_img_aug.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 사전 훈련된 CNN 모델에 전이학습 활용하기\n",
    "- VGG-16 : https://arxiv.org/pdf/1409.1556.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 데이터 불러오기 (위와 동일)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습 데이터 / 검증 데이터 준비\n",
    "# 이미지의 가로,세로 사이즈는 150,150이고 빨강, 녹색, 파랑(RGB)인 3개의 채널이 있으므로 \n",
    "# 출력되는 shape은 (데이터 갯수, 150, 150, 3)의 형태. \n",
    "\n",
    "IMG_DIM = (150, 150)\n",
    "\n",
    "# 학습 데이터 \n",
    "train_files = glob.glob('training_data/*')\n",
    "train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in train_files]\n",
    "train_imgs = np.array(train_imgs)\n",
    "train_labels = [fn.split('/')[1].split('.')[0].strip() for fn in train_files]\n",
    "\n",
    "# 검증 데이터\n",
    "validation_files = glob.glob('validation_data/*')\n",
    "validation_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in validation_files]\n",
    "validation_imgs = np.array(validation_imgs)\n",
    "validation_labels = [fn.split('/')[1].split('.')[0].strip() for fn in validation_files]\n",
    "\n",
    "print('Train dataset shape:', train_imgs.shape, \n",
    "      '\\nValidation dataset shape:', validation_imgs.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 데이터 증강 (위와 동일)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,\n",
    "                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, \n",
    "                                   horizontal_flip=True, fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 하이퍼 파라미터 설정\n",
    "batch_size = 30 # 배치 사이즈 : 반복해서 모델에 전달되는 데이터의 수\n",
    "num_classes = 2 # 클래스 개수 (cat, dog)\n",
    "epochs = 100 #100 # 에포크 : 학습하는동안 모델에 전달하는 전체 데이터 세트를 횟수\n",
    "input_shape = (150, 150, 3) # 입력되는 이미지 사이즈 (가로사이즈, 세로사이즈, 채널 수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 사전 학습된 VGG-16 모델 불러오기\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.applications import vgg16\n",
    "\n",
    "vgg = vgg16.VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "\n",
    "output = vgg.layers[-1].output\n",
    "output = keras.layers.Flatten()(output)\n",
    "\n",
    "vgg_model = Model(vgg.input, output)\n",
    "vgg_model.trainable = False\n",
    "\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-16 모델의 층이 고정되었는지 확인\n",
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-16의 합성곱 블록 4와 5가 학습 가능하도록 설정\n",
    "vgg_model.trainable = True\n",
    "set_trainable = False\n",
    "\n",
    "for layer in vgg_model.layers:\n",
    "    if layer.name in ['block5_conv1', 'block4_conv1']:\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-16 모델의 층이 학습 가능한지 확인\n",
    "\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(vgg_model)\n",
    "model.add(Dense(512, activation='relu', input_dim=input_shape))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.RMSprop(lr=1e-5), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(train_imgs, train_labels_enc, batch_size=batch_size)\n",
    "val_generator = val_datagen.flow(validation_imgs, validation_labels_enc, batch_size=batch_size)\n",
    "\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=epochs,\n",
    "                              validation_data=val_generator, validation_steps=50, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "t = f.suptitle('Pre-trained CNN (Transfer Learning) with Fine-Tuning & Image Augmentation Performance', fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "epoch_list = list(range(1, epochs+1))\n",
    "ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n",
    "ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_xticks(np.arange(0, 101, 10))\n",
    "ax1.set_ylabel('Accuracy Value')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_title('Accuracy')\n",
    "l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
    "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_xticks(np.arange(0, 101, 10))\n",
    "ax2.set_ylabel('Loss Value')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_title('Loss')\n",
    "l2 = ax2.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cats_dogs_tlearn_finetune_img_aug_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from keras.models import load_model\n",
    "import model_evaluation_utils as meu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_aug_cnn = load_model('cats_dogs_cnn_img_aug.h5')\n",
    "tl_img_aug_finetune_cnn = load_model('cats_dogs_tlearn_finetune_img_aug_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이미지 기본 모양\n",
    "IMG_DIM = (150, 150)\n",
    "input_shape = (150, 150, 3)\n",
    "num2class_label_transformer = lambda l: ['cat' if x == 0 else 'dog' for x in l]\n",
    "class2num_label_transformer = lambda l: [0 if x == 'cat' else 1 for x in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 샘플 테스트 이미지로 모델 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img_path = 'my_cat.jpg'\n",
    "# sample_img_path = 'sample_dog.jpg'\n",
    "# sample_img_path = 'sample_cat.jpg'\n",
    "sample_img = load_img(sample_img_path, target_size=IMG_DIM)\n",
    "sample_img_tensor = img_to_array(sample_img)\n",
    "sample_img_tensor = np.expand_dims(sample_img_tensor, axis=0)\n",
    "sample_img_tensor /= 255.\n",
    "\n",
    "print(sample_img_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_img_aug_prediction = num2class_label_transformer(img_aug_cnn.predict_classes(sample_img_tensor, verbose=0))\n",
    "tlearn_cnn_finetune_img_aug_prediction = num2class_label_transformer(tl_img_aug_finetune_cnn.predict_classes(sample_img_tensor, verbose=0))\n",
    "print('Predictions for our sample image:\\n', \n",
    "      '\\nCNN with Img Augmentation:', cnn_img_aug_prediction, \n",
    "      '\\nPre-trained CNN with Fine-tuning & Img Augmentation (Transfer Learning):', tlearn_cnn_finetune_img_aug_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_aug_cnn.predict_proba(sample_img_tensor, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_img_aug_finetune_cnn.predict_proba(sample_img_tensor, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) CNN 모델이 인지한 것을 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_img_aug_finetune_cnn.layers[0].layers[1:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최상위 8개 층에서 추출된 출력:\n",
    "layer_outputs = [layer.output for layer in tl_img_aug_finetune_cnn.layers[0].layers[1:9]]\n",
    "\n",
    "# 모델 입력에 따라 출력을 반환하는 모델을 생성:\n",
    "activation_model = models.Model(inputs=tl_img_aug_finetune_cnn.layers[0].layers[1].input, outputs=layer_outputs)\n",
    "\n",
    "# 층마다 배열이 1개이므로 numpy 배열 형태로 8개의 리스트를 반환\n",
    "activations = activation_model.predict(sample_img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Sample layer shape:', activations[0].shape)\n",
    "print('Sample convolution (activation map) shape:', activations[0][0, :, :, 1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 샘플 특성 지도 추출\n",
    "fig, ax = plt.subplots(1,5, figsize=(16, 6))\n",
    "ax[0].imshow(activations[0][0, :, :, 10], cmap='bone')\n",
    "ax[1].imshow(activations[0][0, :, :, 25], cmap='bone')\n",
    "ax[2].imshow(activations[0][0, :, :, 40], cmap='bone')\n",
    "ax[3].imshow(activations[0][0, :, :, 55], cmap='bone')\n",
    "ax[4].imshow(activations[0][0, :, :, 63], cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# These are the names of the layers, so can have them as part of our plot\n",
    "layer_names = []\n",
    "for layer in tl_img_aug_finetune_cnn.layers[0].layers[1:9]:\n",
    "    layer_names.append(layer.name)\n",
    "\n",
    "images_per_row = 16\n",
    "\n",
    "# Now let's display our feature maps\n",
    "for layer_name, layer_activation in zip(layer_names, activations):\n",
    "    # This is the number of features in the feature map\n",
    "    n_features = layer_activation.shape[-1]\n",
    "\n",
    "    # The feature map has shape (1, size, size, n_features)\n",
    "    size = layer_activation.shape[1]\n",
    "\n",
    "    # We will tile the activation channels in this matrix\n",
    "    n_cols = n_features // images_per_row\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "\n",
    "    # We'll tile each filter into this big horizontal grid\n",
    "    for col in range(n_cols):\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0,\n",
    "                                             :, :,\n",
    "                                             col * images_per_row + row]\n",
    "            # Post-process the feature to make it visually palatable\n",
    "            channel_image -= channel_image.mean()\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size,\n",
    "                         row * size : (row + 1) * size] = channel_image\n",
    "\n",
    "    # Display the grid\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='bone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최상위 층의 특성지도가 원래의 이미지를 더 많이 유지.\n",
    "- 깊은 층 일수록 특성지도는 더 추상적이고 복잡해지며 해석이 어려워짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 테스트 데이터로 수행한 평가 모델 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IMG_DIM = (150, 150)\n",
    "\n",
    "test_files = glob.glob('test_data/*')\n",
    "test_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in test_files]\n",
    "test_imgs = np.array(test_imgs)\n",
    "test_labels = [fn.split('/')[1].split('.')[0].strip() for fn in test_files]\n",
    "\n",
    "test_labels_enc = class2num_label_transformer(test_labels)\n",
    "\n",
    "print('Test dataset shape:', test_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 노말라이즈(스케일링) 및 레이블 인코딩\n",
    "test_imgs_scaled = test_imgs.astype('float32')\n",
    "test_imgs_scaled /= 255\n",
    "\n",
    "test_labels_enc = class2num_label_transformer(test_labels)\n",
    "\n",
    "print(test_labels[0:5], test_labels_enc[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습 할때처럼 generator를 활용하여 예측하는 것도 가능.\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# test_generator = test_datagen.flow(test_imgs, test_labels_enc, batch_size=batch_size, shuffle=False)\n",
    "# predictions = img_aug_cnn.predict_generator(test_generator, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 주어진 데이터만으로 학습한 CNN 모델 (img_aug_cnn) 성능\n",
    "predictions = img_aug_cnn.predict_classes(test_imgs_scaled, verbose=0)\n",
    "predictions = num2class_label_transformer(predictions)\n",
    "\n",
    "meu.display_model_performance_metrics(true_labels=test_labels, predicted_labels=predictions, classes=list(set(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VGG-16기반으로 전이학습한 CNN 모델 (tl_img_aug_finetune_cnn) 성능\n",
    "predictions = tl_img_aug_finetune_cnn.predict_classes(test_imgs_scaled, verbose=0)\n",
    "predictions = num2class_label_transformer(predictions)\n",
    "\n",
    "meu.display_model_performance_metrics(true_labels=test_labels, predicted_labels=predictions, classes=list(set(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ROC 커브 비교\n",
    "meu.plot_model_roc_curve(img_aug_cnn, test_imgs_scaled, \n",
    "                                  true_labels=test_labels_enc, class_names=[0, 1])\n",
    "\n",
    "meu.plot_model_roc_curve(tl_img_aug_finetune_cnn, test_imgs_scaled, \n",
    "                                  true_labels=test_labels_enc, class_names=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}